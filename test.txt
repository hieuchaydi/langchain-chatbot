from typing import Dict, Any, List, Optional
"""
Chat Service Module

ChatService v4.4.3 (Token-Optimized CSKH)
- Kh√¥ng g·ªçi Gemini cho:
  - social
  - small talk
  - deny
  - product inquiry
  - quick reply
- Gemini ch·ªâ l√† fallback classifier
- Gi·ªØ nguy√™n:
  - CSKH routing
  - Hidemium priority
  - query expansion
  - multi-language
  - deny + escalation
"""

import asyncio
import logging
import os
import re

from services.intent_registry import intent_registry
from config.quick_reply import QuickReplyHandler
from models.vector_store import VectorStoreManager, SESSION_MEMORY
from models.db import save_message
from middleware.badword_filter import contains_swear, get_swear_response
from models.gemini_analyzer import analyze_question


LOG_DIR = "log"
os.makedirs(LOG_DIR, exist_ok=True)

pipeline_logger = logging.getLogger("chat_pipeline")
pipeline_logger.setLevel(logging.INFO)
pipeline_logger.propagate = False

if not pipeline_logger.handlers:
    handler = logging.FileHandler(
        os.path.join(LOG_DIR, "chat_pipeline.log"),
        encoding="utf-8"
    )
    formatter = logging.Formatter(
        "%(asctime)s | %(levelname)s | %(message)s"
    )
    handler.setFormatter(formatter)
    pipeline_logger.addHandler(handler)


def log_flow(step: str, data: Optional[Dict[str, Any]] = None):
    if data:
        pipeline_logger.info(f"[FLOW] {step} | {data}")
    else:
        pipeline_logger.info(f"[FLOW] {step}")


# =========================
# SOCIAL / SMALL TALK
# =========================

SOCIAL_RESPONSES = {
    "vi": {
        "greeting": "Ch√†o b·∫°n üëã",
        "thanks": "Kh√¥ng c√≥ g√¨, r·∫•t vui ƒë∆∞·ª£c gi√∫p b·∫°n!",
        "goodbye": "T·∫°m bi·ªát nh√© üëã",
        "introduction": "M√¨nh l√† tr·ª£ l√Ω AI h·ªó tr·ª£ kh√°ch h√†ng, r·∫•t vui ƒë∆∞·ª£c h·ªó tr·ª£ b·∫°n ·∫°.",
        "chitchat": "Ch√†o b·∫°n! M√¨nh c√≥ th·ªÉ h·ªó tr·ª£ b·∫°n v·ªÅ v·∫•n ƒë·ªÅ g√¨ h√¥m nay?",
        "who_are_you": "M√¨nh l√† tr·ª£ l√Ω AI h·ªó tr·ª£ kh√°ch h√†ng c·ªßa c√¥ng ty ·∫°. R·∫•t vui ƒë∆∞·ª£c g·∫∑p b·∫°n!",
        "what_doing": "M√¨nh ƒëang ·ªü ƒë√¢y ch·ªù h·ªó tr·ª£ b·∫°n n√® üòÑ B·∫°n c·∫ßn gi√∫p g√¨ h√¥m nay?",
    },
    "en": {
        "greeting": "Hello üëã",
        "thanks": "You're welcome!",
        "goodbye": "Goodbye üëã",
        "introduction": "I'm an AI customer support assistant designed to help you.",
        "chitchat": "Hi there! How can I help you today?",
        "who_are_you": "I'm your AI customer support assistant. Nice to meet you!",
        "what_doing": "Just here waiting to assist you üòÑ What's on your mind?",
    },
    "zh": {
        "greeting": "‰Ω†Â•Ω üëã",
        "thanks": "‰∏çÂÆ¢Ê∞îÔºÅ",
        "goodbye": "ÂÜçËßÅ üëã",
        "introduction": "ÊàëÊòØAIÂÆ¢Êà∑ÊîØÊåÅÂä©ÊâãÔºåÂæàÈ´òÂÖ¥‰∏∫ÊÇ®ÊúçÂä°„ÄÇ",
        "chitchat": "‰Ω†Â•ΩÔºÅ‰ªäÂ§©ÊàëËÉΩÂ∏ÆÊÇ®‰ªÄ‰πàÔºü",
        "who_are_you": "ÊàëÊòØÊÇ®ÁöÑAIÂÆ¢Êà∑ÊîØÊåÅÂä©ÊâãÔºåÂæàÈ´òÂÖ¥ËÆ§ËØÜÊÇ®ÔºÅ",
        "what_doing": "ÊàëÂú®ËøôÈáåÁ≠âÁùÄÂ∏ÆÊÇ®Âë¢ üòÑ ÊÇ®Êúâ‰ªÄ‰πàÈúÄË¶ÅÔºü",
    },
    "ru": {
        "greeting": "–ü—Ä–∏–≤–µ—Ç üëã",
        "thanks": "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞!",
        "goodbye": "–î–æ —Å–≤–∏–¥–∞–Ω–∏—è üëã",
        "introduction": "–Ø AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤, —Ä–∞–¥ –≤–∞–º –ø–æ–º–æ—á—å.",
        "chitchat": "–ü—Ä–∏–≤–µ—Ç! –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å —Å–µ–≥–æ–¥–Ω—è?",
        "who_are_you": "–Ø –≤–∞—à AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ–¥–¥–µ—Ä–∂–∫–∏. –ü—Ä–∏—è—Ç–Ω–æ –ø–æ–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è!",
        "what_doing": "–Ø –∑–¥–µ—Å—å, —á—Ç–æ–±—ã –ø–æ–º–æ—á—å –≤–∞–º üòÑ –û —á–µ–º –¥—É–º–∞–µ—Ç–µ?",
    },
}


SOCIAL_STARTERS = {
    "vi": [
        "hi", "hello", "hey", "xin ch√†o", "ch√†o", "ch√†o b·∫°n", "ch√†o anh", "ch√†o ch·ªã",
        "b·∫°n l√† ai", "b·∫°n t√™n g√¨", "ai v·∫≠y",
        "ƒëang l√†m g√¨", "l√†m g√¨ ƒë·∫•y", "ƒëang l√†m g√¨ th·∫ø",
        "ch√†o bu·ªïi s√°ng", "ch√†o bu·ªïi chi·ªÅu", "ch√†o bu·ªïi t·ªëi",
    ],
    "en": [
        "hi", "hello", "hey",
        "who are you", "what's your name",
        "what are you doing", "how are you",
        "good morning", "good afternoon", "good evening",
    ],
    "zh": [
        "‰Ω†Â•Ω", "Âó®", "‰Ω†ÊòØË∞Å", "‰Ω†Âè´‰ªÄ‰πàÂêçÂ≠ó",
        "‰Ω†Âú®ÂÅö‰ªÄ‰πà", "‰Ω†Â•ΩÂêó",
    ],
    "ru": [
        "–ø—Ä–∏–≤–µ—Ç", "–∫—Ç–æ —Ç—ã", "–∫–∞–∫ —Ç–µ–±—è –∑–æ–≤—É—Ç",
        "—á–µ–º –∑–∞–Ω–∏–º–∞–µ—à—å—Å—è", "–∫–∞–∫ –¥–µ–ª–∞",
    ],
}


SMALL_TALK_PATTERNS = {
    "vi": {
        r"(b·∫°n|em|m√¨nh).*(kh·ªèe|·ªïn|th·∫ø n√†o)": "M√¨nh kh·ªèe l·∫Øm ·∫°, c·∫£m ∆°n b·∫°n h·ªèi! C√≤n b·∫°n th√¨ sao? üòä",
        r"(ƒëang l√†m g√¨|ƒëang l√†m)": "ƒêang ch·ªù h·ªó tr·ª£ b·∫°n ƒë√¢y ·∫° üòÑ B·∫°n c·∫ßn gi√∫p g√¨ n√†o?",
    },
    "en": {
        r"(you).*(good|fine|how)": "I'm doing great, thanks! How about you? üòä",
        r"(what.*doing)": "Just here to help you out üòÑ What's up?",
    },
    "zh": {
        r"(‰Ω†).*(Â•Ω|ÊÄé‰πàÊ†∑)": "ÊàëÂæàÂ•ΩÔºåË∞¢Ë∞¢ÔºÅÊÇ®Âë¢Ôºü üòä",
        r"(Âú®ÂÅö‰ªÄ‰πà)": "Â∞±Âú®ËøôÈáåÂ∏ÆÊÇ® üòÑ ÊÇ®ÈúÄË¶Å‰ªÄ‰πàÂ∏ÆÂä©Ôºü",
    },
    "ru": {
        r"(—Ç—ã).*(—Ö–æ—Ä–æ—à–æ|–∫–∞–∫)": "–£ –º–µ–Ω—è –≤—Å–µ —Ö–æ—Ä–æ—à–æ, —Å–ø–∞—Å–∏–±–æ! –ê —É –≤–∞—Å? üòä",
        r"(—á–µ–º.*–∑–∞–Ω–∏–º–∞–µ—à—å—Å—è)": "–ü—Ä–æ—Å—Ç–æ –∑–¥–µ—Å—å, —á—Ç–æ–±—ã –ø–æ–º–æ—á—å –≤–∞–º üòÑ –ß—Ç–æ —É –≤–∞—Å?",
    },
}


DENY_KEYWORDS = {
    "vi": ["sai r·ªìi", "kh√¥ng ƒë√∫ng", "kh√¥ng ph·∫£i", "t√¥i kh√¥ng mu·ªën", "kh√¥ng ph·∫£i v·∫≠y", "l·∫°i sai"],
    "en": ["not correct", "wrong", "that's wrong", "incorrect", "not right", "not what i want", "nope", "that's not it"],
    "zh": ["‰∏çÂØπ", "Èîô‰∫Ü", "‰∏çÊòØËøôÊ†∑"],
    "ru": ["–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ", "–Ω–µ —Ç–æ", "–æ—à–∏–±–∫–∞"],
}


PRODUCT_KEYWORDS = {
    "vi": [
        "hidemium", "api hidemium", "hidemium api", "hidemium l√† g√¨",
        "d·ªãch v·ª• hidemium", "hidemium proxy", "·∫©n danh hidemium",
    ],
    "en": [
        "hidemium", "hidemium api", "what is hidemium",
        "hidemium proxy", "tell me about hidemium",
    ],
    "zh": ["hidemium", "hidemium api"],
    "ru": ["hidemium", "hidemium api"],
}


def detect_language(text: str) -> str:
    if re.search(r'[\u4e00-\u9fff]', text):
        return "zh"
    if re.search(r'[\u0400-\u04ff]', text):
        return "ru"
    try:
        text.encode("ascii")
        return "en"
    except UnicodeEncodeError:
        return "vi"


def translate_to_vi(text: str, src_lang: str) -> str:
    if src_lang == "vi":
        return text
    return text


def translate_from_vi(text: str, target_lang: str) -> str:
    if target_lang == "vi":
        return text
    return text


# =========================
# RAG HELPERS
# =========================

def is_valid_chunk(text: str) -> bool:
    text = text.strip()
    if not text or text in {"--", "-", "..."}:
        return False
    if len(text) < 15:
        return False
    return True


def build_answer_from_chunks(
    docs: List[str],
    query: Optional[str] = None,
    max_chars: int = 800
) -> str:
    valid_docs = [d for d in docs if is_valid_chunk(d)]
    if not valid_docs:
        return ""

    best_docs = valid_docs
    if query:
        q = query.lower()
        matched = [d for d in valid_docs if q in d.lower()]
        if matched:
            best_docs = matched

    answer_parts = []
    current_length = 0

    for text in best_docs:
        match = re.search(r"\*\*?A:\*\*?\s*(.+)", text, re.DOTALL | re.IGNORECASE)
        extracted = match.group(1).strip() if match else text.strip()

        extracted = re.sub(r'^[-\*]\s*', '', extracted)
        extracted = re.sub(r'\s+', ' ', extracted)

        if current_length + len(extracted) <= max_chars:
            answer_parts.append(extracted)
            current_length += len(extracted)
        else:
            break

    return "\n".join(answer_parts)


def wrap_cskh_answer(answer: str, lang: str) -> str:
    if not answer:
        return answer

    suffixes = {
        "vi": "B·∫°n c·∫ßn h·ªó tr·ª£ th√™m g√¨ kh√¥ng ·∫°? üòä",
        "en": "Anything else I can help with? üòä",
        "zh": "ËøòÊúâ‰ªÄ‰πàÊàëËÉΩÂ∏ÆÊÇ®ÁöÑÂêóÔºü üòä",
        "ru": "–ß–µ–º –µ—â–µ –º–æ–≥—É –ø–æ–º–æ—á—å? üòä",
    }

    return f"{answer} {suffixes.get(lang, suffixes['en'])}"


def build_alternative_answer(docs: List[str], lang: str) -> str:
    prefixes = {
        "vi": "C√≥ th·ªÉ m√¨nh ƒë√£ hi·ªÉu ch∆∞a ƒë√∫ng tr∆∞·ªùng h·ª£p c·ªßa b·∫°n.\nTrong t√†i li·ªáu hi·ªán c√≥, m√¨nh th·∫•y c√°c th√¥ng tin sau:\n",
        "en": "Maybe I didn't understand your case correctly.\nIn the current documentation, I found the following:\n",
        "zh": "ÂèØËÉΩÊàëÊ≤°ÂÆåÂÖ®ÁêÜËß£ÊÇ®ÁöÑÊÉÖÂÜµ„ÄÇ\nÂú®Áé∞ÊúâÊñáÊ°£‰∏≠ÔºåÊàëÊâæÂà∞‰ª•‰∏ã‰ø°ÊÅØÔºö\n",
        "ru": "–í–æ–∑–º–æ–∂–Ω–æ, —è –Ω–µ —Å–æ–≤—Å–µ–º –ø–æ–Ω—è–ª –≤–∞—à —Å–ª—É—á–∞–π.\n–í –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ —è –Ω–∞—à–µ–ª —Å–ª–µ–¥—É—é—â–µ–µ:\n",
    }

    text = prefixes.get(lang, prefixes["en"])

    for i, d in enumerate(docs[:3]):
        summary_vi = build_answer_from_chunks([d])
        summary = translate_from_vi(summary_vi, lang)
        label = chr(65 + i)
        text += f"‚Ä¢ Tr∆∞·ªùng h·ª£p {label}: {summary}\n" if lang == "vi" else f"‚Ä¢ Case {label}: {summary}\n"

    questions = {
        "vi": "\nB·∫°n ƒëang quan t√¢m tr∆∞·ªùng h·ª£p n√†o ƒë·ªÉ m√¨nh h·ªó tr·ª£ ch√≠nh x√°c h∆°n nh√©?",
        "en": "\nWhich case are you referring to so I can assist more accurately?",
        "zh": "\nÊÇ®ÂÖ≥ÂøÉÂì™‰∏™ÊÉÖÂÜµÔºåËÆ©ÊàëÊõ¥ÂáÜÁ°ÆÂú∞Â∏ÆÂä©ÊÇ®Ôºü",
        "ru": "\n–ö–∞–∫–æ–π —Å–ª—É—á–∞–π –≤–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç, —á—Ç–æ–±—ã —è –º–æ–≥ –ø–æ–º–æ—á—å —Ç–æ—á–Ω–µ–µ?",
    }

    text += questions.get(lang, questions["en"])
    return text


# =========================
# CHAT SERVICE
# =========================

class ChatService:

    def __init__(self):
        self.vector = VectorStoreManager()
        self.quick_reply = QuickReplyHandler()

    async def process_chat_message(
        self,
        message: str,
        session_id: str = "default"
    ) -> Dict[str, Any]:

        pipeline_logger.info("=" * 80)
        pipeline_logger.info(f"[INPUT] {message}")

        message = message.strip()
        if not message:
            return {"response": "Please say something üòÖ"}

        save_message("user", message, session_id=session_id)

        session = SESSION_MEMORY.setdefault(session_id, {})

        user_lang = detect_language(message)
        support_state = session.setdefault("support_state", {
            "phase": "idle",
            "last_query": None,
            "last_answer": None,
            "deny_count": 0,
            "language": user_lang,
            "escalated": False
        })

        support_state["language"] = user_lang

        msg_lc = message.lower()

        # RESET deny_count n·∫øu user KH√îNG c√≤n ph·ªß ƒë·ªãnh
        deny_list = DENY_KEYWORDS.get(user_lang, [])
        if support_state["deny_count"] > 0 and not any(x in msg_lc for x in deny_list):
            support_state["deny_count"] = 0

        # 1) DENY (PH·∫¢I CH·∫†Y TR∆Ø·ªöC PRODUCT PRIORITY)
        if any(x in msg_lc for x in deny_list):
            resp = await self.handle_deny(support_state)
            if support_state["deny_count"] >= 3:
                support_state["escalated"] = True
            save_message("bot", resp, session_id)
            log_flow("handling_deny", {"deny_count": support_state["deny_count"]})
            return {"response": resp, "mode": "cskh_deny"}

        # 2) PRODUCT PRIORITY (guarded)
        product_keywords_all = PRODUCT_KEYWORDS.get(user_lang, []) + PRODUCT_KEYWORDS.get("en", [])
        if any(kw in msg_lc for kw in product_keywords_all) and support_state["deny_count"] == 0:
            log_flow("route_product_inquiry", {"query": message, "lang": user_lang})
            return await self.handle_knowledge_flow(message, support_state, session_id)

        # 3) SMALL TALK
        for pattern, reply in SMALL_TALK_PATTERNS.get(user_lang, {}).items():
            if re.search(pattern, msg_lc):
                save_message("bot", reply, session_id)
                log_flow("small_talk_hit", {"pattern": pattern})
                return {"response": reply, "mode": "small_talk"}

        # 4) SOCIAL HARD MATCH (WORD BOUNDARY FIX)
        starters = SOCIAL_STARTERS.get(user_lang, [])
        for x in starters:
            pattern = r"\b" + re.escape(x) + r"\b"
            if re.search(pattern, msg_lc):
                responses = SOCIAL_RESPONSES.get(user_lang, SOCIAL_RESPONSES["en"])

                if any(y in msg_lc for y in ["l√† ai", "who are you"]):
                    answer = responses["who_are_you"]
                elif any(y in msg_lc for y in ["l√†m g√¨", "doing"]):
                    answer = responses["what_doing"]
                else:
                    answer = responses["chitchat"]

                save_message("bot", answer, session_id)
                log_flow("route_cskh_social_hard", {"answer": answer})
                return {"response": answer, "mode": "social"}

        # 5) BAD WORD
        if contains_swear(message):
            resp = get_swear_response()
            save_message("bot", resp, session_id)
            return {"response": resp}

        # 6) QUICK REPLY
        if len(message) <= 8:
            qr = self.quick_reply.get_quick_response(message)
            if qr:
                save_message("bot", qr, session_id)
                return {"response": qr, "mode": "quick_reply"}

        # ==================================================
        # 7) GEMINI FALLBACK CLASSIFIER (GATED)
        # ==================================================
        intent_type = "knowledge"
        intent = "unknown"

        log_flow("intent_llm_probe", {"message": message})

        try:
            analysis = await asyncio.to_thread(analyze_question, message)
            intent_type = analysis.get("type", "knowledge")
            intent = analysis.get("intent", "unknown")
            log_flow("intent_detected", {"type": intent_type, "intent": intent})
        except Exception as e:
            log_flow("intent_llm_error", {"error": str(e)})

        # 8) SOCIAL FALLBACK
        if intent_type == "social":
            responses = SOCIAL_RESPONSES.get(user_lang, SOCIAL_RESPONSES["en"])
            answer = responses.get("chitchat", responses["chitchat"])
            save_message("bot", answer, session_id)
            return {"response": answer, "mode": "social"}

        # 9) ACTION INTENT
        handler_cls = intent_registry.get(intent_type, intent)
        if handler_cls:
            handler = handler_cls()
            resp = await handler.handle(session)
            return resp

        # 10) DEFAULT KNOWLEDGE
        return await self.handle_knowledge_flow(message, support_state, session_id)

    async def handle_knowledge_flow(
        self,
        message: str,
        support_state: Dict[str, Any],
        session_id: str
    ) -> Dict[str, Any]:

        support_state["phase"] = "answering"

        user_lang = support_state["language"]
        query_vi = translate_to_vi(message, user_lang)

        # reset deny_count CH·ªà khi user h·ªèi c√¢u M·ªöI
        if support_state.get("last_query") and support_state["last_query"] != query_vi:
            support_state["deny_count"] = 0

        support_state["last_query"] = query_vi

        docs = []
        if "hidemium" in query_vi.lower():
            expanded_queries = [
                query_vi,
                "Hidemium API l√† g√¨",
                "Hidemium l√† g√¨",
                "d·ªãch v·ª• Hidemium API",
                "Hidemium proxy anonymous browsing",
                "t√≠nh nƒÉng Hidemium API",
                "c√°ch s·ª≠ d·ª•ng Hidemium",
            ]

            all_docs = []
            for q in expanded_queries:
                d, _, _ = self.vector.query_documents(
                    query=q, user_id=session_id, n_results=15
                )
                all_docs.extend(d)

            seen = set()
            docs = [x for x in all_docs if not (x in seen or seen.add(x))][:40]

            log_flow("query_expansion", {
                "original": query_vi,
                "expanded_count": len(expanded_queries)
            })
        else:
            docs, _, _ = self.vector.query_documents(
                query=query_vi, user_id=session_id, n_results=20
            )

        answer_vi = build_answer_from_chunks(docs, query_vi)

        if not answer_vi or len(answer_vi.strip()) < 30:
            if "hidemium" in query_vi.lower():
                answer_vi = (
                    "Hidemium API l√† b·ªô API cho ph√©p b·∫°n t·∫°o, qu·∫£n l√Ω v√† kh·ªüi ch·∫°y "
                    "c√°c browser profile Hidemium t·ª´ tool b√™n ngo√†i. "
                    "API th∆∞·ªùng d√πng ƒë·ªÉ t√≠ch h·ª£p v·ªõi Puppeteer, Playwright "
                    "ho·∫∑c automation framework ri√™ng.\n\n"
                    "B·∫°n ƒëang mu·ªën:\n"
                    "‚Ä¢ ƒêi·ªÅu khi·ªÉn profile qua API?\n"
                    "‚Ä¢ K·∫øt n·ªëi v·ªõi Puppeteer/Playwright?\n"
                    "‚Ä¢ Hay build tool ri√™ng d√πng profile Hidemium?"
                )
            else:
                answer_vi = (
                    "M√¨nh ch∆∞a t√¨m th·∫•y th√¥ng tin ph√π h·ª£p trong t√†i li·ªáu hi·ªán t·∫°i. "
                    "B·∫°n c√≥ th·ªÉ m√¥ t·∫£ chi ti·∫øt h∆°n ƒë∆∞·ª£c kh√¥ng ·∫°? üòä"
                )

        support_state["last_answer"] = answer_vi

        answer = translate_from_vi(answer_vi, user_lang)
        answer = wrap_cskh_answer(answer, user_lang)

        log_flow("rag_response", {"answer_preview": answer[:150]})
        save_message("bot", answer, session_id)

        return {"response": answer, "mode": "knowledge"}

    async def handle_deny(self, support_state: Dict[str, Any]) -> str:

        support_state["phase"] = "handling_deny"
        support_state["deny_count"] += 1

        last_query_vi = support_state.get("last_query")
        lang = support_state["language"]

        # L·∫¶N 3 ‚Üí escalation
        if support_state["deny_count"] >= 3:
            escalations = {
                "vi": (
                    "M√¨nh xin l·ªói v√¨ ch∆∞a h·ªó tr·ª£ ƒë√∫ng. "
                    "M√¨nh s·∫Ω chuy·ªÉn b·∫°n sang b·ªô ph·∫≠n CSKH nh√©. "
                    "B·∫°n ƒë·ªÉ l·∫°i th√¥ng tin ƒë·ªÉ b√™n m√¨nh li√™n h·ªá h·ªó tr·ª£ ·∫° üòä"
                ),
                "en": (
                    "Sorry I couldn't get it right yet. "
                    "I'll escalate to our support team. "
                    "Please leave your details üòä"
                ),
            }
            return escalations.get(lang, escalations["en"])

        # L·∫¶N 2 ‚Üí √©p cases
        if support_state["deny_count"] == 2 and last_query_vi:
            rephrased = last_query_vi + " c√°c tr∆∞·ªùng h·ª£p"
            docs, _, _ = self.vector.query_documents(
                query=rephrased, user_id="deny", n_results=50
            )

            # fallback c·ª©ng n·∫øu kh√¥ng c√≥ doc
            if not docs:
                hard_cases = {
                    "vi": [
                        "ƒêi·ªÅu khi·ªÉn profile t·ª´ tool kh√°c qua API",
                        "K·∫øt n·ªëi profile v·ªõi Puppeteer / Playwright",
                        "X√¢y tool ri√™ng ƒë·ªÉ qu·∫£n l√Ω profile",
                    ],
                    "en": [
                        "Control profile from another tool via API",
                        "Connect profile with Puppeteer / Playwright",
                        "Build your own tool to manage profiles",
                    ],
                }

                cases = hard_cases.get(lang, hard_cases["en"])

                text = {
                    "vi": "C√≥ th·ªÉ b·∫°n ƒëang n√≥i t·ªõi m·ªôt trong c√°c tr∆∞·ªùng h·ª£p sau:\n",
                    "en": "You might be referring to one of these cases:\n",
                }.get(lang, "You might be referring to one of these cases:\n")

                for i, c in enumerate(cases):
                    label = chr(65 + i)
                    text += (
                        f"‚Ä¢ Tr∆∞·ªùng h·ª£p {label}: {c}\n"
                        if lang == "vi"
                        else f"‚Ä¢ Case {label}: {c}\n"
                    )

                text += {
                    "vi": "\nB·∫°n ƒëang quan t√¢m tr∆∞·ªùng h·ª£p n√†o?",
                    "en": "\nWhich case are you referring to?",
                }.get(lang, "\nWhich case are you referring to?")

                return text

            return build_alternative_answer(docs, lang)

        # L·∫¶N 1 ‚Üí h·ªèi r√µ h∆°n
        if not last_query_vi:
            return {
                "vi": "M√¨nh ch∆∞a r√µ b·∫°n ƒëang ph·ªß ƒë·ªãnh ph·∫ßn n√†o. B·∫°n c√≥ th·ªÉ n√≥i r√µ h∆°n kh√¥ng ·∫°? üòä",
                "en": "I'm not sure what part you're disagreeing with. Could you clarify? üòä",
            }.get(lang, "I'm not sure what part you're disagreeing with. Could you clarify? üòä")

        return {
            "vi": "C√≥ th·ªÉ m√¨nh ch∆∞a hi·ªÉu ƒë√∫ng. B·∫°n c√≥ th·ªÉ n√≥i r√µ h∆°n kh√¥ng ·∫°? üòä",
            "en": "Maybe I misunderstood. Could you clarify? üòä",
        }.get(lang, "Maybe I misunderstood. Could you clarify? üòä")


_chat_service = ChatService()

async def process_chat_message(message: str, session_id: str = "default"):
    return await _chat_service.process_chat_message(message, session_id)
